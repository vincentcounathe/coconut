# improved from gsm_coconut_stabilized

project: coconut-parallel
save_path: /share/sds/vc383/scratch_coconut/gsm-parallel/checkpoints
name: gsm-coconut-parallel-full

only_eval: False

coconut: True
cot: False
no_thoughts: False
no_cot: False

# Coconut curriculum
c_thought: 2
epochs_per_stage: 3
max_latent_stage: 3
pad_latent_to_max: True

# Stabilizers (unchanged)
latent_detach: False
latent_adapter: scale
freeze_schedule: [0, 0, 0, 0]

# Parallel-specific params
parallel_mode: full         # {"triangular","full"}
num_parallel_passes: 4            # K << N to realize speedup
ema_decay: 0.0                    
latent_init: token                # {"token","learned_slot","gaussian"}
latent_init_std: 0.02

# Consistency objectives
tc_weight: 0.00
sd_weight: 0.00
tc_distance: mse                  # {"mse","cos"}
tc_norm: rms                      # {"rms","none"}

parallel_inference: True

# Rest per baseline
save_only_improve: True
uniform_prob: 0.0
model_id: openai-community/gpt2
load_model_path: /share/sds/vc383/scratch_coconut/gsm-cot-fp32/checkpoints/gsm-cot/checkpoint_6
seed: 0
resume: 3
bf16: False
train_path: data/gsm_train.json
val_path: data/gsm_valid.json
reset_optimizer: False
batch_size_training: 32
debug: False
gradient_accumulation_steps: 1
num_epochs: 25
lr: !!float "2e-4"
weight_decay: 0.01
grad_clip_norm: 2
